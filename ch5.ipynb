{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실 함수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평균 제곱 오차 \n",
    "\n",
    "앞에서 선형 계층을 통해 모델을 구축할 수 있음을 배웠다.\n",
    "\n",
    "그렇다면 이제 데이터를 집어넣고 모델이 함수 $f^*$을 잘 근사계산하고 있는지 판단할 수 있어야 한다.\n",
    "\n",
    "**가장 간단한 방법은 해당 모델에 수집한 데이터로 입력을 넣었을 때 원하는 출력이 나오는지** 확인하는 것이다. 이 때 모델에서 반환한 출력은 원래의 출력값 $y$를 모방한 값이므로 $\\hat y$ 라고 하자.\n",
    "\n",
    "$y, \\hat y$의 차이가 크지 않다면 좋은 모델이라고 말할 수 있을 것이다. 이를 수식으로 나타내면 다음과 같다.\n",
    "\n",
    "$$\\begin{align} Loss & = \\sum_{i=1}^{N} \\left \\Vert {y_i - \\hat y_i} \\right \\Vert \\\\\n",
    "& = \\left \\Vert y_i  - f(x_i) \\right \\Vert \\end{align} $$\n",
    "\n",
    "이와 같이 $\\hat y, y$의 차이의 크기를 더한 것을 **손실 값(loss)**라고 한다.\n",
    "\n",
    "따라서 **손실 값이 작을수록 해당 모델은 근사계산하고자 하는 함수 $f^*$를 잘 근사계산했다고 말할 수 있다**는 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 모델 함수는 가중치 파라미터에 의해 동작이 정의된다고 했다.\n",
    "\n",
    "이 모델은 $W$와 $b$를 가중치 파라미터로 갖고 있는다.\n",
    "\n",
    "모델의 가중치 파라미터의 집합을 이제 $\\theta$라고 표현해보자. 즉, $\\theta = {W, b}$이다.\n",
    "\n",
    "그렇다면 모델 함수는 가중치 파라미터 $\\theta$에 의해 정의되므로, $f_{\\theta}$라고 표현되어도 무방하다. 이제 손실 값을 최소화하는 모델을 찾으면 된다.\n",
    "\n",
    "방법으로는 여러 가지가 있겠지만 가장 간단한 방법은 모델 가중치 파라미터의 값을 랜덤하게 바꿔보는 것이다. 그럼 모델의 동작이 바뀌면서 입력에 대한 출력 $\\hat y$가 바뀔 것이다. 따라서 손실 값도 바뀌게 된다. 이전보다 손실 값이 더 줄었다면 더 좋은 가중치 파라미터를 찾았다고 할 수 있다.\n",
    "\n",
    "이 작업을 수월하게 하기 위해 함수로 표현해보자.\n",
    "\n",
    "$$\\zeta(\\theta) = \\sum_{i=1}^{N} \\left \\Vert {y_i - f_{\\theta}(x_i)} \\right \\Vert, \\\\\n",
    "\\text{where} \\theta = {W, b}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 **손실 함수의 출력값을 최소로 만드는 모델의 가중치 파라미터 $\\theta$(함수 입력 값)을 찾기**만 하면 된다.\n",
    "\n",
    "앞에서 언급된 방법으로 하면 매우 오래 시간이 소요된다. 이와 관련하여 효율적인 방법은 다음 절에 배우도록 하겠다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수 선택\n",
    "\n",
    "손실 값의 정의로 타깃 출력 $y$와 모델의 출력 $\\hat y$의 차이라 했는데, 이 차이를 정의하는 방법은 여러 가지가 있다.\n",
    "\n",
    "#### L1\n",
    "\n",
    "L1 norm은 n차원 벡터의 각 요소들 사이의 차이에 대한 절댓값을 모두 더한 것이다.\n",
    "\n",
    "$$\\left \\Vert y - \\hat y \\right \\Vert = \\sum_{i=1}^{n} \\left | y_i - \\hat{y_i} \\right |, \\\\\n",
    "where y \\in R^n, \\hat y \\in R^n$$\n",
    "\n",
    "#### L2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 norm은 유클리디안 거리로도 잘 알려져 있다.\n",
    "\n",
    "손실 함수에 L2 norm을 활용하면 벡터의 각 요소들 간 차이에 때해 제곱을 구하여 모두 더한 것이다. 따라서 이렇게 표현된다.\n",
    "\n",
    "$$ {\\left \\Vert y - \\hat y \\right \\Vert}_2 = \\sqrt {\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}, \\\\\n",
    "where y \\in R^n, \\hat y \\in R^n$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE\n",
    "\n",
    "제곱급 평균 오차는 L2 노름과 유사하나, 제곱근을 구하기 전에 **벡터의 차원 크기인 n으로 나누어 평균을 취한다**. 수식은 다음과 같다.\n",
    "\n",
    "$$RMSE(y, \\hat y) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat y_i)^2}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이름과 같이 오차(error)에 제곱(squared)을 구하고, 평균(mean)을 취해서 제곱근(root)을 씌우는 것을 볼 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE\n",
    "\n",
    "RMSE에서 제곱근을 뜻하는 R이 빠졌다. 즉, RMSE에 제곱을 취한 것과 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Loss 실습\n",
    "\n",
    "MSE 손실 함수를 파이토치로 직접 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def mse(x_hat, x):\n",
    "    y = ((x - x_hat)**2).mean()\n",
    "    return y\n",
    "\n",
    "x = torch.FloatTensor([[1,1], [2,2]])\n",
    "x_hat = torch.zeros(4).reshape(2,2)\n",
    "\n",
    "print(mse(x_hat, x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 사용하기\n",
    "\n",
    "MSE 손실 함수도 파이토치에서 기본적으로 제공된다. 파이토치 내장 MSE 손실 함수는 다음과 같이 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.mse_loss(x_hat, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 함수에는 reduction이라는 인자를 통해 MSE 손실 값을 구할 때 차원 감소 연산(평균)에 대한 설정을 할 수 있다.\n",
    "\n",
    "sum, none 등을 선택하여 원하는 대로 MSE 손실 함수의 출력값을 얻을 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn 사용하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn을 사용하여 손실 함수를 출력할 수 있다.\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "mse_loss(x_hat, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "둘의 차이는 거의 없다.\n",
    "\n",
    "하지만 torch.nn을 사용하게 되면 nn.Module의 하위 클래스 내부에 선언하기 때문에 계층(layer)의 하나처럼 취급할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c084588ddc99ecfa5893987730956e72e2b095d02e836974b6e39a38a952fd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
