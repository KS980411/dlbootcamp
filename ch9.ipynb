{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심층신경망 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층신경망\n",
    "\n",
    "우리는 비선형 함수 형태를 근사계산해야 할 수도 있다. 만약 데이터의 흐름이 비선형이라면 선형 회귀와 로지스틱으로는 예측할 수 없음.\n",
    "\n",
    "기존의 머신러닝 기법들로는 비선형적이고 높은 차원의 데이터를 다루는 데에 어려움이 많았다.\n",
    "\n",
    "심층신경망이란 것이 이러한 문제를 해결하는 데 큰 힘을 발휘하기 시작. 따라서 심층신경망으로 이러한 문제를 어떻게 해결하는지 알아보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층신경망이란?\n",
    "\n",
    "심층신경망은 **서로 다른 선형 계층을 깊게 쌓아 구성**할 수 있다.\n",
    "\n",
    "하지만 단순히 선형 계층을 많이 쌓는 것으로 충분할까?\n",
    "\n",
    "$$ h = x \\cdot W_1 + b_1 \\\\\n",
    "y = h \\cdot W_2 + b_2 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 두 개의 선형 계층을 가진 모델을 생각해보자. 이 모델은 그럼 두 개의 계층을 지닌 심층신경망이 되는 것일까?\n",
    "\n",
    "이를 정리해보면, 또 다른 선형 계층이 나오게 된다($W \\cdot x + b$의 형태). 즉, **두 선형 계층을 통과하는 것은 또 다른 하나의 선형 계층을 통과하는 것과 같다**라는 것을 확인할 수 있다.\n",
    "\n",
    "그래서 이런 방법으로는 **비선형 문제를 풀 수 없음**.\n",
    "\n",
    "그렇다면 어떻게 풀어야할까? 가장 간단한 방법으로 **선형 계층을 쌓을 때 그 사이에 비선형 함수**를 끼어넣는 것이 있다. 비선형 함수는 앞에서 배운 활성화 함수, 즉 시그모이드나 tanh함수들이 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층신경망의 크기\n",
    "\n",
    "심층신경망으로 세상에 존재하는 그 어떤 형태의 함수도 근사계산할 수 있음이 증명되었다.\n",
    "\n",
    "보통 신경망을 구성할 때는 **계층이 진행될수록 너비가 줄어드는 형태로 설계**를 하게 된다. 이 때 너비가 줄어드는 양을 조절하거나 계층을 더 깊게 쌓을수록 네트워크의 표현 능력은 일반적으로 더 향상된다.\n",
    "\n",
    "따라서 **신경망을 더 넓고, 깊게 쌓아 더 복잡하고 어려운 데이터의 관계를 배우거나 문제를 풀 수 있다**. \n",
    "\n",
    "하지만 깊이가 깊어지거나 너비가 넓어지게 되면 **계층들의 가중치 파라미터 크기가 늘어나게** 된다. 경사하강법을 통해 최적화해야 하는 공간의 차원 크기도 같이 늘어나게 된다.\n",
    "\n",
    "그렇기 때문에 신경망이 커지더라도 최적화에 어려움을 겪을 수 있어 실제로는 성능 향상의 한계가 있을 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층신경망의 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층신경망의 학습 개요\n",
    "\n",
    "심층신경망 또한 경사하강법을 활용하여 각 가중치 파라미터를 업데이트한다.\n",
    "\n",
    "심층신경망은 계층이 많아진 만큼, 가중치 파라미터도 늘어나게 된다. 따라서 업데이트되어야 할 가중치 파라미터들이 늘어난 만큼 손실 함수에 대해 미분을 해야 하는 일도 늘어나게 된다.\n",
    "\n",
    "더 큰 문제는 입력으로부터 가까운 계층의 파라미터일수록 **훨씬 복잡한 함수 꼴**이 된다는 것이다. 이것을 미분하는 일은 **신경망이 깊어질수록 점점 더 비효율적이게 될 것**이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파\n",
    "\n",
    "역전파 알고리즘은 chain rule을 통해 구현 됨.\n",
    "\n",
    "$$ y = g(f(x)) \\\\\n",
    "y = g(x), h = f(x) \\\\\n",
    "\\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial h} \\frac{\\partial h}{\\partial x} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y가 g와 f로 이루어진 합성함수일 때, 위 명제가 성립한다. 이것을 chain rule이라고 함.\n",
    "\n",
    "따라서 이런 성질을 이용하여 **심층 신경망의 미분도 간단한 수식에 대한 미분의 곱으로 표현**될 수 있음. 간단한 수식들에 대한 미분은 다른 계층의 미분을 구할 때 다시 재활용할 수 있어 훨씬 효율적인 계산이 가능하다.\n",
    "\n",
    "미분 계산 과정이 **계속해서 뒤 쪽 계층으로 전달되는 것**을 **역전파**라고 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 역전파 알고리즘의 수식\n",
    "\n",
    "심층신경망을 사용하여 회귀 문제를 풀고자 할 때, 다음 수식과 같이 MSE 손실 함수를 활용할 수 있음.\n",
    "\n",
    "$$\\zeta(\\theta) = \\sum_{i=1}^{N} \\left \\Vert y_i - \\hat y_i \\right \\|_2^2$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층신경망이 구성될 때, 이들 심층 신경망의 파라미터를 하나하나 업데이트 하는 것은 매우 비효울적임.\n",
    "\n",
    "그렇지만 chain rule을 이용해 간단한 수식들의 미분 곱으로 표현할 수 있음.\n",
    "\n",
    "(3층 신경망 가정)\n",
    "$$\\frac {\\partial \\zeta}{\\partial W_3} = \\frac {\\partial \\zeta}{\\partial \\hat y} \\frac {\\partial \\hat y}{\\partial W_3}\n",
    "\\\\ \\frac {\\partial \\zeta}{\\partial W_2} = \\frac {\\partial \\zeta}{\\partial \\hat y} \\frac {\\partial \\hat y}{\\partial h_2} \\frac{\\partial h_2}{\\partial W_2}\n",
    "\\\\ \\cdots$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(주의!) $\\frac {\\partial W_2}{\\partial W_3}$과 같은꼴은 없다!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레디언트 소실 문제 \n",
    "\n",
    "심층신경망이 너무 깊어지면 최적화가 잘 수행되지 않는 문제가 종종 발생.\n",
    "\n",
    "특히 입력에 가까운 계층의 가중치 파라미터가 잘 업데이트되지 않아 생기는데 이러한 것을 **그레디언트 소실 문제**라고 부른다.\n",
    "\n",
    "다음과 같은 계층을 생각해보자.\n",
    "\n",
    "$$\\zeta(\\theta) = \\sum^{N}_{i=1} \\left \\Vert y_i - \\hat y_i \\right \\Vert _2^2\n",
    "\\\\ \\hat y = h_{2,i} \\cdot W_3 + b_3\n",
    "\\\\ h_{2,i} = \\sigma(\\tilde h_{2,i})\n",
    "\\\\ \\tilde h_{2,i} = h_{1,i} \\cdot W_2 + b_2\n",
    "\\\\ h_{1,i} = \\sigma(\\tilde h_{1,i})\n",
    "\\\\ \\tilde h_{1,i} = x_{i}^T \\cdot W_1 + b_1$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 계층이 추가되었으므로, tilde(틸다)가 추가되었다.\n",
    "\n",
    "즉, 선형 계층의 결과값을 $\\tilde h$ 으로 표현하고, 이것을 활성 함수에 넣어 얻은 결과를 $h$으로 배정했다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데, 시그모이드는 **전 구간에서 1보다 한참 작은 기울기**를 가지며, 탄에이치의 경우에는 **전 구간에서 1보다 같거나 작은 값**을 가진다.\n",
    "\n",
    "따라서 계속해서 chain rule로 역전파 알고리즘을 수행할 때, 계속해서 1보다 작은 값이 반복적으로 곱해진다.\n",
    "\n",
    "gradient로 업데이트를 해야 하는데, 이것이 0과 가까워지는 것이다.\n",
    "\n",
    "이렇게 깊어지는 신경망에서 역전파 과정으로 그레디언트가 소실되어 입력과 가까운 계층이 잘 학습되지 않는 문제를 **그레디언트 소실**이라고 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU\n",
    "\n",
    "시그모이드와 같은 비선형 활성 함수는 미분 계수가 전 구간에서 1보다 작기 때문에 발생한다.\n",
    "\n",
    "ReLU는 이러한 기존 활성 함수의 단점을 보완하기 위해 제안된 새로운 활성화 함수이다.\n",
    "\n",
    "$$ y = ReLU(x) = max(0,x)$$\n",
    "\n",
    "보다시피, 양수 구간에서 **기울기가 1**이기 때문에 매우 빠른 최적화가 간으하다.\n",
    "\n",
    "하지만 음수 구간에서의 기울기가 0이 되므로 ReLU의 입력이 0이 되면 뒷 단의 가중치 파라미터들에 학습을 진행할 수 없다.\n",
    "\n",
    "혹시 데이터셋의 모든 샘플이 ReLU의 음수 구간으로 입력되면, 해당 ReLU에 값을 전달해주는 노드와 관련된 가중치 파라미터들은 이후 학습 과정에서 영원히 업데이트될 수 없는 문제가 발생한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 문제를 해결하기 위해 Leaky ReLU가 제안되었다.\n",
    "\n",
    "$$y = LeakyReLU(x) = max(a \\cdot x, x), where 0 \\le a < 1$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음수 구간에서 비록 1보다 작지만 0이 아닌 기울기를 갖는 것이 특징이다.\n",
    "\n",
    "LeakyReLU가 ReLU의 문제점을 보완한 것은 맞지만, 데이터에 따라 LeakyReLU가 잘 맞을수도, ReLU가 잘 맞을 수도 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Regression 실습\n",
    "\n",
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choeunsol/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['TARGET'] = boston.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 속성을 통해 심층신경망을 학습시켜 보자. 이에 앞서, 좀 더 쉽고 수월한 최적화 및 성능 향상을 위해 표준 스케일링도 입력 값을 정규화해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.4132</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>-0.6258</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.3872</td>\n",
       "      <td>-0.4181</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.4152</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>-0.2345</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>-0.7166</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.5008</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.4134</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>-0.7737</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.9830</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.4078</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>-0.6684</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>-0.8653</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.4150</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>-0.3628</td>\n",
       "      <td>0.4347</td>\n",
       "      <td>-0.6132</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.6691</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM      ZN   INDUS    CHAS     NOX      RM     AGE     DIS     RAD  \\\n",
       "501 -0.4132 -0.4877  0.1157 -0.2726  0.1581  0.4393  0.0187 -0.6258 -0.9828   \n",
       "502 -0.4152 -0.4877  0.1157 -0.2726  0.1581 -0.2345  0.2889 -0.7166 -0.9828   \n",
       "503 -0.4134 -0.4877  0.1157 -0.2726  0.1581  0.9850  0.7974 -0.7737 -0.9828   \n",
       "504 -0.4078 -0.4877  0.1157 -0.2726  0.1581  0.7257  0.7370 -0.6684 -0.9828   \n",
       "505 -0.4150 -0.4877  0.1157 -0.2726  0.1581 -0.3628  0.4347 -0.6132 -0.9828   \n",
       "\n",
       "        TAX  PTRATIO       B   LSTAT  TARGET  \n",
       "501 -0.8032   1.1765  0.3872 -0.4181    22.4  \n",
       "502 -0.8032   1.1765  0.4411 -0.5008    20.6  \n",
       "503 -0.8032   1.1765  0.4411 -0.9830    23.9  \n",
       "504 -0.8032   1.1765  0.4032 -0.8653    22.0  \n",
       "505 -0.8032   1.1765  0.4411 -0.6691    11.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df.values[:, :-1])\n",
    "df.values[:, :-1] = scaler.transform(df.values[:, :-1]).round(4)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화를 적용하기 전, **데이터셋의 분포의 특징을 파악하고 어떤 정규화 방법이 가장 어울릴지 결정**해야 한다.\n",
    "\n",
    "보스턴 주택 가격 데이터셋의 각 열이 **정규분포**를 따른다고 가정하고 표준 스케일링을 적용했다. 다음 테이블은 표준 스케일링을 적용한 결과를 보여주고 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "data = torch.from_numpy(df.values).float()\n",
    "y = data[:, -1:]\n",
    "x = data[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "\n",
    "n_epochs = 200000\n",
    "learning_rate = 1e-4\n",
    "print_interval = 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 심층신경망을 정의하자.\n",
    "\n",
    "**마지막 계층은 활성 함수를 씌우지 않도록** 주의!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(3,3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(3,3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(3, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.layer(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(x.shape[-1], x.shape[-1])\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/8zsbg3r51rs_vl832mx18q_00000gn/T/ipykernel_3977/2606333117.py:3: UserWarning: Using a target size (torch.Size([506, 1])) that is different to the input size (torch.Size([506, 13])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000: loss = 1.0022e+01\n",
      "Epoch 20000: loss = 9.2713e+00\n",
      "Epoch 30000: loss = 9.0126e+00\n",
      "Epoch 40000: loss = 8.8279e+00\n",
      "Epoch 50000: loss = 8.6944e+00\n",
      "Epoch 60000: loss = 8.5939e+00\n",
      "Epoch 70000: loss = 8.5118e+00\n",
      "Epoch 80000: loss = 8.4524e+00\n",
      "Epoch 90000: loss = 8.3992e+00\n",
      "Epoch 100000: loss = 8.3428e+00\n",
      "Epoch 110000: loss = 8.2946e+00\n",
      "Epoch 120000: loss = 8.2022e+00\n",
      "Epoch 130000: loss = 8.0899e+00\n",
      "Epoch 140000: loss = 8.0530e+00\n",
      "Epoch 150000: loss = 7.9715e+00\n",
      "Epoch 160000: loss = 7.7899e+00\n",
      "Epoch 170000: loss = 7.6288e+00\n",
      "Epoch 180000: loss = 7.4861e+00\n",
      "Epoch 190000: loss = 7.3655e+00\n",
      "Epoch 200000: loss = 7.2679e+00\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1) % print_interval == 0:\n",
    "        print('Epoch %d: loss = %.4e' % (i+1, loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (506, 14), indices imply (506, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/choeunsol/Python/dl_study/dlbootcamp/ch9.ipynb 셀 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/choeunsol/Python/dl_study/dlbootcamp/ch9.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(torch\u001b[39m.\u001b[39;49mcat([y, y_hat], dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy(), columns \u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39my_hat\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choeunsol/Python/dl_study/dlbootcamp/ch9.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sns\u001b[39m.\u001b[39mpairplot(df, height \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choeunsol/Python/dl_study/dlbootcamp/ch9.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    692\u001b[0m         )\n\u001b[1;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    695\u001b[0m             data,\n\u001b[1;32m    696\u001b[0m             index,\n\u001b[1;32m    697\u001b[0m             columns,\n\u001b[1;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    701\u001b[0m         )\n\u001b[1;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    353\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (506, 14), indices imply (506, 2)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(torch.cat([y, y_hat], dim = 1).detach().numpy(), columns = [\"y\", \"y_hat\"])\n",
    "sns.pairplot(df, height = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 13])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c084588ddc99ecfa5893987730956e72e2b095d02e836974b6e39a38a952fd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
